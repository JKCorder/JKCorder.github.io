<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4 Measures of association: t-test | Applied Statistics for Political Science</title>
<meta name="author" content="J.K. Corder">
<meta name="description" content="4.1 What is the t-test? In many research situations, the \(Y\) variable is some type of scale - either an interval or an ordinal variable. This would include concrete measures like household...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="4 Measures of association: t-test | Applied Statistics for Political Science">
<meta property="og:type" content="book">
<meta property="og:description" content="4.1 What is the t-test? In many research situations, the \(Y\) variable is some type of scale - either an interval or an ordinal variable. This would include concrete measures like household...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="4 Measures of association: t-test | Applied Statistics for Political Science">
<meta name="twitter:description" content="4.1 What is the t-test? In many research situations, the \(Y\) variable is some type of scale - either an interval or an ordinal variable. This would include concrete measures like household...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.10/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Applied Statistics for Political Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">About this book</a></li>
<li><a class="" href="data-science-political-science-and-public-policy.html"><span class="header-section-number">1</span> Data science, political science, and public policy</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">2</span> Descriptive statistics</a></li>
<li><a class="" href="an-introduction-to-measures-of-association-correlation.html"><span class="header-section-number">3</span> An introduction to measures of association: correlation</a></li>
<li><a class="active" href="measures-of-association-t-test.html"><span class="header-section-number">4</span> Measures of association: t-test</a></li>
<li><a class="" href="measures-of-association-chi-square.html"><span class="header-section-number">5</span> Measures of association: Chi-square</a></li>
<li><a class="" href="regression.html"><span class="header-section-number">6</span> Regression</a></li>
<li><a class="" href="statistical-models-with-many-predictors.html"><span class="header-section-number">7</span> Statistical models with many predictors</a></li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="about-the-author.html">About the author</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/JKCorder/RMD-for-AppStats-chapters">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="measures-of-association-t-test" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Measures of association: t-test<a class="anchor" aria-label="anchor" href="#measures-of-association-t-test"><i class="fas fa-link"></i></a>
</h1>
<div id="what-is-the-t-test" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> What is the t-test?<a class="anchor" aria-label="anchor" href="#what-is-the-t-test"><i class="fas fa-link"></i></a>
</h2>
<p>In many research situations, the <span class="math inline">\(Y\)</span> variable is some type of scale - either an interval or an ordinal variable. This would include concrete measures like household income, year of education, or age and concepts that we order in a meaningful way – like ideology (from extreme liberal to extreme conservative) or party identification (from strong Democrat to strong Republican) or a feeling thermometer (from 0 – don’t like it – to 100- really like it). But the <span class="math inline">\(X\)</span> variable may be a category: race, marital status, gender, employment status. If you are interested in determining the relationship between two variables when <span class="math inline">\(Y\)</span> is a scale, and <span class="math inline">\(X\)</span> is a category, then a t-test is the appropriate measure of association.</p>
<p>We have used statistics (mean, median, and standard deviation) to describe individual variables. We will use a simple test statistic (t-test) to determine if two groups in a sample are different. T-tests are most appropriate and informative when you compare two groups (male/female, straight ticket / split ticket, Northern/Southern) on a continuous scale.</p>
<p>Recall that we use measures of association to describing relationships between variables. We identify a dependent variable (<span class="math inline">\(Y\)</span>), an independent variable (<span class="math inline">\(X\)</span>), and we have a theory about how <span class="math inline">\(X\)</span> influences <span class="math inline">\(Y\)</span>. The measure of association helps use be precise and clear about three things:
the direction of relationship (does changing from one category of <span class="math inline">\(X\)</span> to another increase (+) <span class="math inline">\(Y\)</span> or decrease (-) <span class="math inline">\(Y\)</span>
the size of the effect (does <span class="math inline">\(X\)</span> have a big impact on <span class="math inline">\(Y\)</span> or small?)
whether or not effects in the sample are statistically significant (Could the observed effect be due to chance or sampling error)?</p>
<p>We covered size and direction in Chapter 3, so the focus of this chapter is broadening your understanding of statistical significance. To do this, we talk about inference and introduce the concept of a sampling distribution. After the preliminaries, we review some t-test output related to the National Rifle Association (NRA) feeling thermometer. At the end of the chapter, you should have a sense of what statistical significance means.</p>
</div>
<div id="what-is-inference-and-what-does-this-have-to-do-with-random-samples" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> What is inference? And what does this have to do with random samples?<a class="anchor" aria-label="anchor" href="#what-is-inference-and-what-does-this-have-to-do-with-random-samples"><i class="fas fa-link"></i></a>
</h2>
<p>Inference is learning about something we cannot observe from something we can observe. We can observe samples. We cannot observe and measure populations. Inference is learning about populations from samples. In order to make an unbiased inference about a population from a small sample, the only requirement is the sample is random. Any individual in the population has an equal chance of showing up in the sample.</p>
<p>Polling organizations devote a lot of time and energy to figure out how to create random samples. Today, pollsters may rely on face-to-face, phone or web-based contacts to collect data – each strategy has its challenges and face-to-face is obviously very costly. All of these strategies introduce what is known as survey response bias or <em>non-response bias</em> – individuals who are willing to respond may be different than individuals not willing to respond. Before caller id and cell phones, a pollster could randomly dial phone numbers and, as long as the people who answered were willing to talk, the sample would be random. Today, people who are not interested in politics may be the phones who never answer an unidentified caller and cell phone users may not answer at all. There are technical fixes for all of this, but it remains a continuing challenge to make sure a sample is random.</p>
<p>Even if we do have a random sample we know we will be uncertain about how close our sample resembles the larger population – we know that, even if the sample is completely random, we can never have a perfect representation of the population there will be what is known as <em>sampling error</em>. We could get a sample that, by chance, has a lot of Republicans – that would give us a flawed estimate of the average party identification.</p>
<p>We use random sampling since we want to make inferences about the population from our sample. If the samples are random, then descriptive statistics – measures of dispersion or central tendency – also have <em>sampling distributions</em> with known properties. This turns out to be a crucial insight that underpins the way we use statistics to improve what we can say we know from a sample. We explore the sampling distribution of the mean so you can see exactly how this works.</p>
</div>
<div id="sampling-distribution-of-the-mean" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Sampling distribution of the mean<a class="anchor" aria-label="anchor" href="#sampling-distribution-of-the-mean"><i class="fas fa-link"></i></a>
</h2>
<p>The mean has a sampling distribution – we didn’t talk about this in Chapter 2 since I wanted to focus on interpretation of descriptive statistics rather than the sampling distributions.
Consider an experiment: If we took 1,000 random samples (or any really large number of samples) from a population it happens to be the case that the sample means – the means from each of the 1,000 samples - are distributed normally with some features we understand,</p>
<p>The mean of the sample means is equal to the population mean (the sample mean is an unbiased estimate of the population mean). On average, our random samples will be accurate.</p>
<p>The standard deviation of the sampling distribution will be equal to the standard deviation of the variable in the population (approximated with standard deviation of the sample) divided by the square root of the sample size. Formally:</p>
<p><span class="math display">\[ \sigma_{M} = \frac{\sigma}{\sqrt{n}} \]</span></p>
<p>As the sample size gets larger, the width of the sampling distribution gets smaller. If your sample starts to approach the population size, you can imagine no sample would be very different from the population. With very small samples, you could get means very different from the true population mean.</p>
<p>Since we know the mean and standard deviation of this normal distribution, we can exploit other things we know about the normal distribution. Figure 4.1 shows a standard normal distribution - a distribution with a mean of zero and a standard deviation of one. We know – from statistics that 95% of the area covered by this distribution if between -2 and +2 standard deviations from the mean.</p>
<p>So, since our sampling distribution is also normal, we know that any 95% of the samples we draw in our experiment would be within -2/+2 standard deviations of the mean. This is a powerful fact we will leverage to make an inference about the population from our sample.</p>
<div id="figure-4.1-the-standard-normal-distribution" class="section level4" number="4.3.0.1">
<h4>
<span class="header-section-number">4.3.0.1</span> Figure 4.1 The standard normal distribution<a class="anchor" aria-label="anchor" href="#figure-4.1-the-standard-normal-distribution"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-figure"><img src="04-ttest_files/figure-html/figure1-1.png" width="672"></div>
</div>
<div id="calculating-the-margin-of-error" class="section level3 unnumbered">
<h3>Calculating the margin of error<a class="anchor" aria-label="anchor" href="#calculating-the-margin-of-error"><i class="fas fa-link"></i></a>
</h3>
<p>We know that 95% of the reported values from a large number of repeated samples will be within approximately 2.0 standard deviations (technically, 1.96) of the population mean. The margin of error associated with any random sample is:</p>
<p><span class="math display">\[ME=2*\sigma_{M}=2*\frac{\sigma}{\sqrt{n}}\]</span>
If you have in front of you data from a single random sample – you can use software to compute the mean and standard deviation, and knowing the sample size, you can report an estimate for the population mean +/- the margin of error. Table 4.1 reports the descriptive statistics for age in the 2020 ANES. The average respondent in the sample is 47.3 years old. What does that tell us about the population?</p>
<div id="table-4.1.-descriptive-statistics-for-age-in-the-2020-anes" class="section level4 unnumbered">
<h4>Table 4.1. Descriptive statistics for age in the 2020 ANES<a class="anchor" aria-label="anchor" href="#table-4.1.-descriptive-statistics-for-age-in-the-2020-anes"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left"></th>
<th align="center">Descriptive statistics</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">N</td>
<td align="center">7159</td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td align="center">47.26</td>
</tr>
<tr class="odd">
<td align="left">Median</td>
<td align="center">47</td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="center">303.74</td>
</tr>
<tr class="odd">
<td align="left">Standard deviation</td>
<td align="center">17.43</td>
</tr>
</tbody>
</table></div>
<p>Using the formula above, the standard error of the mean would be:</p>
<p><span class="math display">\[ \sigma_M=17.43 / \sqrt{7159} = 0.206 \]</span>
<span class="math display">\[ ME = 2 * .206=0.412\]</span>
We know (with 95% certainty) that the population mean is +/- 2 standard error of the means from the sample mean. The <em>95% confidence interval</em> is 47.26 +/- 0.412 years. That is remarkable – we can be very confident that we know the true age of the actual very large US electorate within less than about 5 months (0.4 of a year).</p>
<p>The key lesson: the “margin of error” associated with the survey response is 2 times the standard error of the mean.</p>
</div>
</div>
<div id="margin-of-error-and-sample-size" class="section level3 unnumbered">
<h3>Margin of error and sample size<a class="anchor" aria-label="anchor" href="#margin-of-error-and-sample-size"><i class="fas fa-link"></i></a>
</h3>
<p>For a question that has a Yes/No (1/0) answer, the standard deviation cannot be more than about 0.5 for large samples. The highest standard deviation would be a 50% yes and 50% no response or mean 0.5. Half of the responses (“1”s) would be 0.5 above the mean. Half of the responses would be 0.5 below the mean. So the calculation for the standard deviation would be about 0.5 for as n/n-1 gets close to 1 (large samples)</p>
<!-- No need to include this: -->
<!-- $$\sigma_x=\sqrt{((n/2)*(0.00-0.50)^2+(n/2)*(1.0-0.5)^2) / (n-1)}$$ -->
<!-- This number is about 0.5 for larger samples. -->
<p>So for a sample of 1000 voters the standard error of the mean would be:</p>
<p><span class="math display">\[\sigma_M = 0.5/ \sqrt{n} = 0.50 / \sqrt{1000} =  0.16\]</span>
So we could be confident that our population mean would be within +/- 2 x the standard error = 0.032 or 3.2% of the sample mean of 50%.</p>
<p>As you see on the news, if you ask 1,000 people if they favor or do not favor a particular proposal, the margin of error is roughly +/- 3%</p>
<p>One implication to note here. What if we were to consider how the collection of additional information would improve our estimates? Since the standard error of the mean drops as the sample size gets larger (we are dividing by the square root of the number of observations), each new observation improves our estimates. The figure below shows this improvement for the 0/1 question example above. Assuming the standard deviation is 0.5, we can see how the margin of error declines as the sample size increases.</p>
<div id="figure-4.2.-margin-of-error-if-sample-standard-deviation-0.5-for-samples-from-100-to-2500" class="section level4 unnumbered">
<h4>Figure 4.2. Margin of error if sample standard deviation ~ 0.5, for samples from 100 to 2500<a class="anchor" aria-label="anchor" href="#figure-4.2.-margin-of-error-if-sample-standard-deviation-0.5-for-samples-from-100-to-2500"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-figure"><img src="04-ttest_files/figure-html/figure2-1.png" width="672"></div>
<p>You can see that there is an obvious and large gain in improvement as you move from 500 to 1,000 observations, but much smaller as you move from 1,000 to 1,500. You may see much larger samples in practice - for two reasons. First, some times we need very precise estimates - you wouldn’t, for instance, want to estimate the unemployment rate at +/- 2 percent - economic policy choices require a more much precision. Second, you might be interested in subsets of the population. If you want a decent margin of error associated with attitudes or behavior of minorities, then you would need a very large overall sample, so that the minority sample of interest was closer to 1,500.</p>
</div>
</div>
</div>
<div id="t-test-comparing-means-for-two-groups" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> T-test: comparing means for two groups<a class="anchor" aria-label="anchor" href="#t-test-comparing-means-for-two-groups"><i class="fas fa-link"></i></a>
</h2>
<p>If we have a sample mean for some variable for some group, we can use that information along with the number in each group and the standard deviation of the responses in each group to make an inference about the mean for that group in the population. We could estimate the average age of women, for instnace. A t-test extends this idea to compare samples of two groups – the idea is that we treat our two groups as two independent samples from the same population. If they are in fact identical then they should have the same sample mean. If the sample means are different, then maybe the two groups are different in the population.</p>
<p>The two-sample t-test permits you to test the difference in means across two categories of respondents (2 samples). The output reveals the direction, size, and significance of the effect – Group 1 has a higher or lower mean than Group 2, the difference between the two means is large or small, and the difference between the two means is statistically significant or not.</p>
<p>The sampling distribution of the differences in two means has the t-distribution. We use the t-distribution to evaluate our observed t to determine if observed differences are statistically significant,</p>
<p>The computation is not difficult. Recall that <span class="math inline">\(\mu\)</span> designates the mean, <span class="math inline">\(\sigma\)</span> designates the standard deviation, and <span class="math inline">\(n\)</span> designates sample size. If you have simple descriptive statistics for two samples, you could easily calculate this by hand. Note that <span class="math inline">\(\mu_1\)</span> designates the mean for group 1 and <span class="math inline">\(\mu_2\)</span> designates the mean for group 2.</p>
<p><span class="math display">\[t=\frac{(\mu_1-\mu_2)}  {\sqrt{(\sigma_1^2/n_1)+(\sigma_2^2/n_2)}}\]</span></p>
<p>Note: if the sample means are identical, the value of t is zero. As the sample means diverge, the value of t will increase.</p>
<div id="the-t-distribution" class="section level3" number="4.4.1">
<h3>
<span class="header-section-number">4.4.1</span> The t distribution<a class="anchor" aria-label="anchor" href="#the-t-distribution"><i class="fas fa-link"></i></a>
</h3>
<p>Why the “t” distribution? The difference between two means is normally distributed for large samples. The t-distribution approximates this normal distribution in large samples. For small samples, the distribution of differences in the mean is not quite normal. This discrepancy was noted by an experimental brewer at Guinness (W.S. Gossett). Since quality control could involve only small samples of ingredients (malt, hops), the statisticians required a test statistic that performed well for small samples. The t-distribution was widely used after this insight. Gossett and Pearson (the statistician most closely associated with correlation) worked together for a short time at and published their findings in 1896 (correlation/Pearson), 1900 (chi-square/Pearson) and 1908 (t-distribution/Gossett). For details see <span class="citation"><a href="references.html#ref-porter1986" role="doc-biblioref">Porter</a> (<a href="references.html#ref-porter1986" role="doc-biblioref">1986</a>)</span> or <span class="citation"><a href="references.html#ref-ziliak2008" role="doc-biblioref">Ziliak</a> (<a href="references.html#ref-ziliak2008" role="doc-biblioref">2008</a>)</span>.</p>
<p>Later work – attributed to Fisher – resulted in the rule-of-thumb: if a t test value is larger than +2 or smaller than -2, the observed difference in means is statistically significant (more on this below!).</p>
</div>
</div>
<div id="an-application-feelings-toward-the-national-rifle-association" class="section level2" number="4.5">
<h2>
<span class="header-section-number">4.5</span> An application: Feelings toward the National Rifle Association<a class="anchor" aria-label="anchor" href="#an-application-feelings-toward-the-national-rifle-association"><i class="fas fa-link"></i></a>
</h2>
<p>The ANES includes a number of variables that are all feeling thermometers. A “0” indicates that you do not like the group, person or symbol that the thermometer refers to. A “100” indicates you very much like that group, symbol or person.</p>
<p>There is a feeling thermomemter for the NRA. Other group thermometers include the CDC, unions, the military, and big business. Figure 4.3 summarizes the distribution of the NRA thermometer. You can see that most people are neutral, but there are a substantial number who have negative feelings (0) and a large number with positive feelings (75 and 100). Table 4.3 reports the descriptive statistics for the NRA feeling thermometer for the entire sample.</p>
<div id="figure-4.3.-feelings-toward-the-nra" class="section level4 unnumbered">
<h4>Figure 4.3. Feelings toward the NRA<a class="anchor" aria-label="anchor" href="#figure-4.3.-feelings-toward-the-nra"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-figure"><img src="04-ttest_files/figure-html/figure-1.png" width="672"></div>
</div>
<div id="table-4.2.-descriptive-statistics.-nra-feeling-thermometer" class="section level4 unnumbered">
<h4>Table 4.2. Descriptive statistics. NRA feeling thermometer<a class="anchor" aria-label="anchor" href="#table-4.2.-descriptive-statistics.-nra-feeling-thermometer"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left"></th>
<th align="center">Descriptive statistics</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">N</td>
<td align="center">6992</td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td align="center">51.36</td>
</tr>
<tr class="odd">
<td align="left">Median</td>
<td align="center">50</td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="center">1159.48</td>
</tr>
<tr class="odd">
<td align="left">Standard deviation</td>
<td align="center">34.05</td>
</tr>
</tbody>
</table></div>
<p>The 95% confidence interval in this case would be:</p>
<p><span class="math display">\[ 51.36 +/-  (2 * 34.05 / \sqrt{6992}) = 51.36 +/- 0.41 \]</span></p>
<p>You don’t have to calculate this by hand - the information will be included in the output you use for the worksheets and papers. Again, this is precise - we know, with some certainty, that the population average is between 50.95 and 51.77.</p>
<p>We can replicate this calculation to compare smaller samples – men compared to women, white compared to minority. Instead of using the mean and standard error of the mean for the entire sample, we look at and compare two groups. If we can be 95% confident that the group means are different in the population, then we know we can safely make an inference about the population from our sample.</p>
</div>
<div id="gender-and-feelings-toward-the-nra" class="section level3 unnumbered">
<h3>Gender and feelings toward the NRA<a class="anchor" aria-label="anchor" href="#gender-and-feelings-toward-the-nra"><i class="fas fa-link"></i></a>
</h3>
<p>Will men and women have different attitudes toward the NRA? A lot of media coverage after the 2016 election focused on women’s activism and women’s voting, assuming or expecting that women would overwhelmingly support Democratic candidates, particular presidential nominee Hillary Clinton. Given that the Democratic party is more likely to advocate stronger restrictions on gun access, maybe women would dislike the NRA? We can test that expectation with a t-test. The results of this test are summarized in Table 4.3.</p>
<div id="table-4.3.-gender-and-the-nra-feeling-thermometer" class="section level4 unnumbered">
<h4>Table 4.3. Gender and the NRA feeling thermometer<a class="anchor" aria-label="anchor" href="#table-4.3.-gender-and-the-nra-feeling-thermometer"><i class="fas fa-link"></i></a>
</h4>
<pre><code>Mean for Women = 49.60146 
 Mean for Men = 53.01543 
 t-test =  -4.174524 
 p =  0.000</code></pre>
<p>We only need to look at three numbers to understand this output – the average for men was 53.0 and the average for women was 49.06 – a small difference, but men slightly warmer. The significance level or p-value associated with this test is 0.000. What does this mean?</p>
<p>The actual value of the t-test is -4.04 and we use that number to come up with a significance level (also called a p-value). If there was no relationship between gender and the NRA thermometer (same exact means for men and women), the t-test would be 0.0 and the significance level would be 1.0. If the significance level is below 0.05, then we can be 95% confident that the groups are different in the population. In Table 4.1 the significance level (p) is less than 0.05, something less 0.000.)</p>
<p>All statistics we use will be accompanied by a measure of significance – often denoted as “p” or the probability value. For our purposes, “p” is the probability that a test statistic of some value could be observed in a sample drawn from a population where the actual or true value of the test statistic is zero. There is a 0.00% probability that we could observe a t-test of -4.043 in the ANES even if men and women had identical average NRA responses in the population</p>
<p>Note: this is very specific type of inference – we can learn something about the population
from our small sample. If p &lt; .05 then the observed difference between the two groups is statistically significant – this an arbitrary standard but a convention in social science. We will discuss this in a more systematic in the chapter on chi-square, but, for now, just remember the convention – p must be less than 0.05</p>
<p>This example also illustrates a key difference between “statistically significance” and “meaningful” - the difference between men and women is very small, a couple of points on the 100 point thermometer - so while we would observe a difference between men and women in the broader population, any differences would be very small.</p>
<p>Remember that we always report/discuss three things with a measure of association – size, direction, and significance. If a result is not significant, you can ignore size and direction – there is no effect, no link between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
<div id="race-and-feelings-toward-the-nra" class="section level3 unnumbered">
<h3>Race and feelings toward the NRA<a class="anchor" aria-label="anchor" href="#race-and-feelings-toward-the-nra"><i class="fas fa-link"></i></a>
</h3>
<p>Will white and minority respondents have different attitudes toward the NRA? The NRA is closely tied to the Repubican Party, so might expect that this would translate into very different attitudes toward the NRA between whites and minorities. Results of a t-test are reproduced as Table 4.4.</p>
<div id="table-4.4.-race-and-the-nra" class="section level4 unnumbered">
<h4>Table 4.4. Race and the NRA<a class="anchor" aria-label="anchor" href="#table-4.4.-race-and-the-nra"><i class="fas fa-link"></i></a>
</h4>
<pre><code>Mean for Minority (Black, Hispanic, or other) = 44.01692 
 Mean for White = 54.64682 
 t-test =  -11.72829 
 p =  0.000</code></pre>
<p>Again, three pieces of information tell the story. Race is a categorical or nominal variable with a couple of categories: 1. White, 2. Black, 3. Asian, 4. Native American, 5. Hispanic, 6. Other. The t-test permits us to compare White respondents (&lt;2 on the scale) with all minorities (&gt;=2). The average for white respondents was 54.64, but the average for minority respondents was 44.01 – much lower. The significance level in this case was again 0.000, much lower than 0.05. We can be confident that, in the larger population, white respondents have more favorable views of the NRA. Since the difference in means between White and Minority respondents is much larger than the difference between women and men, we know that race is a better predictor for understanding how someone feels about the NRA.</p>
</div>
</div>
</div>
<div id="conclusion-1" class="section level2" number="4.6">
<h2>
<span class="header-section-number">4.6</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion-1"><i class="fas fa-link"></i></a>
</h2>
<p>The t-test is a simple way to compare two groups and to verify that any differences between groups are not simply due to chance (sampling error). If we see a difference in sample means that is large enough to be statistically significant, we can be confident that repeated or larger samples would produce the same result.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="an-introduction-to-measures-of-association-correlation.html"><span class="header-section-number">3</span> An introduction to measures of association: correlation</a></div>
<div class="next"><a href="measures-of-association-chi-square.html"><span class="header-section-number">5</span> Measures of association: Chi-square</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#measures-of-association-t-test"><span class="header-section-number">4</span> Measures of association: t-test</a></li>
<li><a class="nav-link" href="#what-is-the-t-test"><span class="header-section-number">4.1</span> What is the t-test?</a></li>
<li><a class="nav-link" href="#what-is-inference-and-what-does-this-have-to-do-with-random-samples"><span class="header-section-number">4.2</span> What is inference? And what does this have to do with random samples?</a></li>
<li>
<a class="nav-link" href="#sampling-distribution-of-the-mean"><span class="header-section-number">4.3</span> Sampling distribution of the mean</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#calculating-the-margin-of-error">Calculating the margin of error</a></li>
<li><a class="nav-link" href="#margin-of-error-and-sample-size">Margin of error and sample size</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#t-test-comparing-means-for-two-groups"><span class="header-section-number">4.4</span> T-test: comparing means for two groups</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#the-t-distribution"><span class="header-section-number">4.4.1</span> The t distribution</a></li></ul>
</li>
<li>
<a class="nav-link" href="#an-application-feelings-toward-the-national-rifle-association"><span class="header-section-number">4.5</span> An application: Feelings toward the National Rifle Association</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#gender-and-feelings-toward-the-nra">Gender and feelings toward the NRA</a></li>
<li><a class="nav-link" href="#race-and-feelings-toward-the-nra">Race and feelings toward the NRA</a></li>
</ul>
</li>
<li><a class="nav-link" href="#conclusion-1"><span class="header-section-number">4.6</span> Conclusion</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/JKCorder/RMD-for-AppStats-chapters/blob/master/04-ttest.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/JKCorder/RMD-for-AppStats-chapters/edit/master/04-ttest.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Applied Statistics for Political Science</strong>" was written by J.K. Corder. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
