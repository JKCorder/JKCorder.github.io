<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Regression | Applied Statistics for Political Science</title>
<meta name="author" content="J.K. Corder">
<meta name="description" content="This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 6 Regression | Applied Statistics for Political Science">
<meta property="og:type" content="book">
<meta property="og:description" content="This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Regression | Applied Statistics for Political Science">
<meta name="twitter:description" content="This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.10/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Applied Statistics for Political Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">About this book</a></li>
<li><a class="" href="data-science-political-science-and-public-policy.html"><span class="header-section-number">1</span> Data science, political science, and public policy</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">2</span> Descriptive statistics</a></li>
<li><a class="" href="an-introduction-to-measures-of-association-correlation.html"><span class="header-section-number">3</span> An introduction to measures of association: correlation</a></li>
<li><a class="" href="measures-of-association-t-test.html"><span class="header-section-number">4</span> Measures of association: t-test</a></li>
<li><a class="" href="measures-of-association-chi-square.html"><span class="header-section-number">5</span> Measures of association: Chi-square</a></li>
<li><a class="active" href="regression.html"><span class="header-section-number">6</span> Regression</a></li>
<li><a class="" href="statistical-models-with-many-predictors.html"><span class="header-section-number">7</span> Statistical models with many predictors</a></li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="about-the-author.html">About the author</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/JKCorder/RMD-for-AppStats-chapters">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="regression" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Regression<a class="anchor" aria-label="anchor" href="#regression"><i class="fas fa-link"></i></a>
</h1>
<p>This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are interested in learning about or understanding, maybe why some people turn out to vote, or why they select a particular candidate, or whether or not they buy a product, or if they are diagnosed with lung cancer. We then select a number of things that we think we could use to predict these outcomes – a theory drives these choices. For turnout, is the person a partisan, are they educated? For a diagnosis of lung cancer, are they a smoker, are they older or younger? We then use data to test the link between the factors we think matter – the predictors – and the outcome of interest. OLS is the technique that we use to determine which factors do or do not matter.</p>
<p>Regression is widely used in a variety of contexts – from program evaluation to marketing to campaigns. If you work in an organization that routinely collects and analyzes data, someone in the organization will be using statistical models to make sense of that data and OLS may be one of the tools they use.</p>
<div id="why-not-just-use-simple-measures-of-association" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Why not just use simple measures of association?<a class="anchor" aria-label="anchor" href="#why-not-just-use-simple-measures-of-association"><i class="fas fa-link"></i></a>
</h2>
<p>The measures of association introduced in earlier chapters permitted us to evaluate the link between some dependent variable (Y) and some independent variable (X) with the specific objective of determining:</p>
<ul>
<li>What is the direction of the effect of X on Y?</li>
<li>Is this effect large or small?</li>
<li>Is the sample effect statistically significant? (Can we infer something about the population from the data in our sample?)</li>
</ul>
<p>There are two important limitations to these measures of association.</p>
<p>First, we have a limited ability to convey or understand the magnitude of the relationship. If we observe a correlation of 0.4 between income and education, what does that mean? Yes, this would indicate that highly educated respondents are more likely to be high income, but how much income does a year of education add? What is the difference in predicted income between a high school graduate and a college graduate? This ambiguity also means that is challenging to directly compare the size of two effects evaluated with two different measures of association. How does the influence of race on party id (measured with a t-test) compare to the influence of income on party id (measured with a correlation)?</p>
<p>A second limitation is that we can only examine the effect of a single variable at one time – what if we expect that two or more variables are jointly responsible for the observed level of Y?</p>
<p>An alternative to measures of association - the simple linear model – or regression – or Ordinary Least Squares regression – or OLS – permits us to manage both of these problems. In this chapter, we focus on a simple two variable model – which helps with problem of communicating specific information about the size of the effect. In Chapter 7, we extend the model to include more than one X variable, to manage the second limitation above.</p>
</div>
<div id="ordinary-least-squares-regression-ols" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Ordinary Least Squares regression (OLS)<a class="anchor" aria-label="anchor" href="#ordinary-least-squares-regression-ols"><i class="fas fa-link"></i></a>
</h2>
<p>Linear regression assumes a particular “functional form” for the relationship between X and Y, specifically that the relationship between X and Y can be summarized with a line (rather than a curve, or some other shape). A linear model takes this form:</p>
<p><span class="math display">\[Y=\beta_0+\beta_1X+\epsilon\]</span></p>
<ul>
<li><p>Y and X are known (data)</p></li>
<li><p><span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are estimated.</p></li>
<li><p><span class="math inline">\(e\)</span> is a random error</p></li>
</ul>
<p>We are principally interested in <span class="math inline">\(\beta_1\)</span> and we wish to know two things:</p>
<ul>
<li><p>What can we infer about the population from our observed <span class="math inline">\(\beta_1\)</span>?</p></li>
<li><p>What does the observed <span class="math inline">\(\beta_1\)</span> tell us about the relationship between Xand Y in the sample?</p></li>
</ul>
<p>The relationship between X and Y is assumed to be linear. This assumption imposes some structure on the link between X and Y which permits us to summarize the link between X and Y with a few parameters. If you recall high school geometry, you might remember that formula for a line is:</p>
<p><span class="math display">\[y=mx+b\]</span>
A line is fully and completely described by two parameters, <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span>.</p>
<ul>
<li><p><span class="math inline">\(b\)</span> is the intercept (the point where the line crosses the vertical axis, <span class="math inline">\(x=0\)</span>)</p></li>
<li><p><span class="math inline">\(m\)</span> is the slope (rise/run) or <span class="math inline">\(\Delta{Y} / \Delta{X}\)</span></p></li>
</ul>
<p>The linear model takes the same form:</p>
<p><span class="math display">\[Y=\beta_0+\beta_1X\]</span></p>
<ul>
<li><p><span class="math inline">\(\beta_0\)</span> is the intercept</p></li>
<li><p><span class="math inline">\(\beta_1\)</span> is the slope (change in Y for every one unit change in X). So,</p></li>
</ul>
<p><span class="math display">\[\beta_1=\frac{\Delta{Y}}{\Delta{X}}\]</span></p>
<p>And, rearranging terms,</p>
<p><span class="math display">\[\Delta{Y} = \Delta{X}*\beta_1\]</span></p>
<p>This calculation - the size of the change in Y given a particular change in X - will be the key way that we interpret and compare the size of effects using OLS.</p>
<div id="graphing-relationships-between-two-variables" class="section level3 unnumbered">
<h3>Graphing relationships between two variables<a class="anchor" aria-label="anchor" href="#graphing-relationships-between-two-variables"><i class="fas fa-link"></i></a>
</h3>
<p>The relationship between two variables may be linear, or it could take some other form – U-shaped or a curve. One way to understand the utility and use of the linear model is to produce a scatterplot of X and Y to see what it means to assume the relationship is linear. The examples below draws on data published by <span class="citation">Pollock (2011)</span> in an introductory text on social science statistics. The dependent variable (Y) is the percentage of state legislators who are women and the independent or predictor variable (X) is the percentage of state population who are Christian – “adhere to a Christian faith.”</p>
<p>A simple scatter plot of this data for the 50 U.S. states is reproduced as Figure 1, below.</p>
<p>Figure 1. <strong>Scatterplot of women in the state legislature as a function of the proportion of state residents who are Christian.</strong> {-}</p>
<div class="inline-figure"><img src="images/states_scatter.png" width="80%"></div>
<p>Experiment with sketching the line in the figure above that you think best describes the link between the two variables. The line is obviously downward sloping: there are a higher proportion of women in the legislature in states that have a lower proportion of Christian adherents. But the line could be fairly steep - passing through 40 in the upper left and approach zero for X=80. Or the line could be fairly flat – passing through 30 in the upper left and approach 10 for X=80</p>
<p>What is best way to draw a line that describes the relationship between X and Y?</p>
<p>We are interested in the two parameters or numbers that describe the line that summarizes the relationship between X and Y – the slope and the intercept. What criteria should we use to pick one line over another? Maybe the distance between points and the line (lowest average error)? Maybe the squared distance between the points and the line (lowest sum of squared errors)? The second criteria – minimize squared error – is the approach we use. The actual regression line is added to the data in Figure 2, below.</p>
<p>Figure 2. <strong>Scatterplot of women in the state legislature as a function of the proportion of state residents who are Christian, with OLS line.</strong></p>
<div class="inline-figure"><img src="images/states_OLS.png" width="80%"></div>
<p>The line that best fits the data – that minimizes the sum of the squared distance between each point and the line – has a slope of -0.35 We can say some very specific things about the 50 states in the sample with this number. Since Y is the percentage of state legislators who are women and X is the percentage of state population who are Christian, we know from the formula above the <span class="math inline">\(\Delta{Y} = \Delta{X}*\beta_1\)</span> So if we compared a state with 70 percent Christian adherents to a state with 50 percent Christian adherents (<span class="math inline">\(\Delta{X}\)</span>=70-50 or 20), we would expect to see -0.35*20 or a 7 point drop in the predicted percentage of female legislators.</p>
</div>
<div id="computation-in-the-simple-linear-model" class="section level3 unnumbered">
<h3>Computation in the simple linear model<a class="anchor" aria-label="anchor" href="#computation-in-the-simple-linear-model"><i class="fas fa-link"></i></a>
</h3>
<p>Regression or OLS summarizes the data with a line that minimizes the sum of the squared error term (<span class="math inline">\(\epsilon^2\)</span>). For the bivariate model (one X predicting Y), the computation of <span class="math inline">\(\beta_1\)</span> is simple. The sum of squared errors for any linear regression is minimized if:</p>
<p><span class="math display">\[\beta_1 =\frac{\sum((X-\mu_x)(Y-\mu_y))} {\sum(X-\mu_x)^2} \]</span></p>
<p>In words, the covariance of X and Y divided by the variance of X.</p>
<p>You can find the mathematical proof that gives the result in most introductory statistics texts.</p>
<p>One we have a value for <span class="math inline">\(\beta_1\)</span>, we can then calculate the intercept:</p>
<p><span class="math display">\[\beta_0=\mu_y-(\mu_x*\beta_1)\]</span></p>
<p>In words, the mean of Y minus the product of the mean of X and <span class="math inline">\(\beta_1\)</span>.</p>
<p>We don’t care much about the constant term since we are mainly interested in comparing the levels across groups – group differences are going to matter more than whether all groups are high or all groups are low on Y. The formula for the intercept makes sure that average value of X is associated with the average value of Y. If you rearrange the terms to solve for <span class="math inline">\(\mu_y\)</span> above, you can see that this approach will work.</p>
</div>
<div id="how-restrictive-is-the-assumption-that-the-relationship-is-linear" class="section level3 unnumbered">
<h3>How restrictive is the assumption that the relationship is linear?<a class="anchor" aria-label="anchor" href="#how-restrictive-is-the-assumption-that-the-relationship-is-linear"><i class="fas fa-link"></i></a>
</h3>
<p>The scatterplot in Figure 2 reveals two things about the data. First, there is a lot of error – this is a “noisy” relationship. States with 60 percent Christian adherents range from 5 percent to 35 percent females in the legislator. The second thing we learn is that, in this case, it appears reasonable to use a line to describe the data. We can evaluate this directly by permitting X and Y to be linked in a way other than a line. For an example, see Figure 3. The points are summarized with what is known as local “smoother” – so the squared distance between the points and the line is minimized, but the path of the line is determined by a handful of points in a narrow range of X, rather than the entire sample. Even with this very flexible approach, it appears the relationship is close to linear.</p>
<p>Figure 3. <strong>Scatterplot of women in the state legislature as a function of the proportion of state residents who are Christian, with local smoother. </strong></p>
<div class="inline-figure"><img src="images/states_smooth.png" width="80%"></div>
</div>
</div>
<div id="interpreting-regression-coefficients" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Interpreting regression coefficients<a class="anchor" aria-label="anchor" href="#interpreting-regression-coefficients"><i class="fas fa-link"></i></a>
</h2>
<p>The linear model assumes Y is a linear function of X. Data are used to test if the relationship between X and Y, the slope of the line, is positive, negative, or zero. You should have an idea of what you expect to observe before you generate the output. As was the case with measures of association, this expectation is formally labeled as the “alternative hypothesis.” In the simple linear model, we test our expectations by examining the sign (negative or positive) of <span class="math inline">\(\beta_1\)</span>.</p>
<p>A t-test is used to determine if the difference between the observed <span class="math inline">\(\beta_1\)</span> and zero is statistically significant. The null hypothesis is that <span class="math inline">\(\beta_1=0\)</span> in the population. The alternative hypothesis <span class="math inline">\(\beta_1\not=0\)</span> (not equal to zero).</p>
<p>If p&lt;0.05, then in the population <span class="math inline">\(\beta_1\)</span> is not equal to zero. (Formally, you reject the null hypothesis). The relationship between X and Y is statistically significant.</p>
<p>To see how regression works in practice, we use two examples – the link between the the Donald Trump feeling thermometer and party id and the link between income and party identification (introduced in Chapter 1).</p>
<div id="example-feelings-toward-donald-trump-and-party-identification" class="section level4 unnumbered">
<h4>Example: Feelings toward Donald Trump and party identification<a class="anchor" aria-label="anchor" href="#example-feelings-toward-donald-trump-and-party-identification"><i class="fas fa-link"></i></a>
</h4>
<p>How are attitudes about Donald Trump related to party id? Following the approach used in earlier chapters, the link between the Donald Trump feeling thermometer and and party identification is summarized in a line chart of group means. You can see that, on average, Strong Republicans love Donald Trump while Strong Democrats do not.</p>
<p>Figure 4. <strong>Donald Trump support by party identification</strong></p>
<div class="inline-figure"><img src="06-ols_files/figure-html/figure64-1.png" width="672"></div>
<p>So what exactly would a regression tell us? To get a sense of what we might expect, consider two questions. What exactly would you expect the feeling thermometer response to be for a Strong Democrat? What would you expect the feeling thermometer response to be for a Strong Republican? If you answered 85 for Strong Democrats and 25 for Strong Republicans, then you are expecting the slope of the regression line to be 10. Why is this the case? Recall the formula for the slope:</p>
<p><span class="math display">\[\beta_1=\Delta{Y}/\Delta{X}\]</span></p>
<p>So, if you expect the difference between strong Democrats and strong Republicans to be about 60 (<span class="math inline">\(\Delta{Y}\)</span>) and we know that the scale for party id ranges from 1 to 7, so <span class="math inline">\(\Delta{X}\)</span> is 7-1 or 6. We know that our expected slope is:</p>
<p><span class="math display">\[60/6 = 10\]</span></p>
<p>Review and make sure you understand the calculation in this example.</p>
<p>Part of the regression output for this model is reproduced as Table 1. We will first focus on the <em>coefficients</em> - the column of numbers next to the variable labels.</p>
<p>Table 1. *Donald Trump Trump feeling thermometer as a function of party id**</p>
<pre><code>
======================================================
                     Feeling Thermometer, Donald Trump
------------------------------------------------------
Party identification             13.726***            
                                 p = 0.000            
                                                      
Constant                        -14.977***            
                                 p = 0.000            
                                                      
N                                  7,336              
R2                                 0.596              
Adjusted R2                        0.596              
======================================================</code></pre>
<p>For every unit increase in party id from 0-&gt;1, or from 1-&gt;2, the feeling thermometer increases by 13.7 points.</p>
<p>So the difference between strong Democrats (1) and strong Republicans (7) is equal to (7-1)*13.7 or 82 points! Even larger than we expected.</p>
<p>Notice the logic here: take the highest possible value of X and subtract the lowest possible value of X. Multiply that number times the slope coefficient. The approximate size of the effect in the sample is:</p>
<p><span class="math display">\[(X_{max}-X_{min}) * \beta_1\]</span></p>
<p>Notice that the significance level associated with the coefficient is below 0.05 (p=0.000). This relationship is statistically significant. We can be confident that, in the population, strong Republicans have much higher average feeling thermometer responses than strong Democrats.</p>
</div>
<div id="example-party-id-and-income-1" class="section level3 unnumbered">
<h3>Example: Party id and income<a class="anchor" aria-label="anchor" href="#example-party-id-and-income-1"><i class="fas fa-link"></i></a>
</h3>
<p>In Chapter 1 we looked at the link between income and party identification, expecting that high income voters are more likely to identify with the Republican party than with the Democratic party. If Y is party id from 1 to 7 with “7” designating strong Republicans and X is income (on a scale from “1” designating $5,000 or lower household income and “22” designating $250,000 more), then <span class="math inline">\(\beta_1\)</span> should be positive.</p>
<p>The output from a linear regression testing the link between party id and income is reproduced as Table 2.</p>
<p>Table 2. <strong>Party identification as a function of party id</strong></p>
<pre><code>
================================
            Party identification
--------------------------------
Income             0.007*       
                 p = 0.086      
                                
Constant          3.783***      
                 p = 0.000      
                                
N                  7,652        
R2                 0.0004       
Adjusted R2        0.0003       
================================</code></pre>
<p>What do we learn? For every unit of income gained on the 22 point scale, your party id increases by 0.007. So households with an income more than $250,000 (22) will really be no higher on the party id scale than households with an income of under $9,999 (1), specifically ((22-1)*0.007)=0.15 points higher on the 1-7 scale – not very much - and we can also see that p-value is 0.086 so this result is not statistically significant. Consistent with what we saw in Chapter 3, there is no linear relationship between income and party id in 2020.</p>
<p>Interpretation of the meaning of the coefficient (<span class="math inline">\(\beta_1\)</span>) is the key to explaining the results of a regression.</p>
</div>
</div>
<div id="hypothesis-testing-using-ols" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Hypothesis testing using OLS<a class="anchor" aria-label="anchor" href="#hypothesis-testing-using-ols"><i class="fas fa-link"></i></a>
</h2>
<p>In addition to using the output from the linear regression to learn about the direction and size the relationship between X and Y in the sample, we also use the output to assess statistical significance and to evaluate how well the model fits the data.</p>
<div id="a-technical-note-on-the-t-test" class="section level3 unnumbered">
<h3>A technical note on the t-test<a class="anchor" aria-label="anchor" href="#a-technical-note-on-the-t-test"><i class="fas fa-link"></i></a>
</h3>
<p>The t-test is simply a one-sample t-test of whether or not <span class="math inline">\(\beta_1\)</span>=0.</p>
<p><span class="math display">\[t=\frac{\beta_1-0}{\sigma_{\beta_1}} \]</span></p>
<p>The top term is simply the difference between the observed coefficient and zero. The bottom term is the standard deviation for the coefficient. What is this number?</p>
</div>
<div id="the-sampling-error-or-standard-deviation-of-beta_1" class="section level3 unnumbered">
<h3>The sampling error or standard deviation of <span class="math inline">\(\beta_1\)</span><a class="anchor" aria-label="anchor" href="#the-sampling-error-or-standard-deviation-of-beta_1"><i class="fas fa-link"></i></a>
</h3>
<p>The slope coefficient has a sampling distribution just like other measures of association. If you took a number of samples, the average of the slopes would be the population slope and the standard deviation of the slope coefficient would be:</p>
<p><span class="math display">\[\sigma_{\beta_1} =\frac{\sum\epsilon^2} {\sum(X_i-\mu_x)^2 *(n-2)}\]</span></p>
<p>In words, the sum of squared errors divided by the variance of X times n-2</p>
<p>This means we would expect to be very uncertain about estimates – to see a high; variance or standard deviation for <span class="math inline">\(\beta_1\)</span> - a lot of uncertainty under three conditions</p>
<ul>
<li>when n is not large (n-2 is small)</li>
<li>when the range of X is narrow (variance of X is small) or,</li>
<li>when the there is a lot of error or noise (sum of squared errors is large).</li>
</ul>
<p>Note the research design implications – if the goal is precision - to minimize the sampling variance of <span class="math inline">\(\beta_1\)</span>, then we would like: large n, sample values across the range of X, and a well-specified model (low errors).</p>
</div>
</div>
<div id="evaluating-goodness-of-fit" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> Evaluating goodness-of-fit<a class="anchor" aria-label="anchor" href="#evaluating-goodness-of-fit"><i class="fas fa-link"></i></a>
</h2>
<p>In addition to the coefficients and significance test, most regression output includes a useful and commonly used measure of the “goodness-of-fit” for each model estimated: the R<sup>2</sup> (or R-squared). The calculation is below:</p>
<p><span class="math display">\[R^2=1-\frac{\sum(Y-\widehat{Y})^2}{\sum(Y-\mu_y)^2}\]</span></p>
<p>The top half of the second term in the equation is designated the “residual sum of squares”: the sum of the differences of any individual Y from the predicted Y (Ŷ). This is some times labeled “error sum of squares.”</p>
<p>The bottom of the second term of the equation is the total sum of squares, which is the same as the variance of Y.</p>
<p>The value of R<sup>2</sup> is bounded between zero and one. You can never do worse than guessing that everyone in a sample will take the mean value of a variable. If then the second term of the equation above become 1 and the R<sup>2</sup> =0.</p>
<p>If, on the other hand, you your model perfectly predicted the outcome (Ŷ equals Y for each observation), then the second term becomes zero and the R<sup>2</sup> would be one. R<sup>2</sup> is therefore bounded between zero and one. A low R<sup>2</sup> – closer to zero - indicates the model does not fit the data very well. In the example above, the R<sup>2</sup> is 0.0004, so this is a model that does not fit the data at all.</p>
<div id="using-r2-in-practice" class="section level3 unnumbered">
<h3>Using R<sup>2</sup> in practice<a class="anchor" aria-label="anchor" href="#using-r2-in-practice"><i class="fas fa-link"></i></a>
</h3>
<p>R<sup>2</sup> is not useful to compare different types of models (different levels of aggregation or very different dependent variables). R<sup>2</sup> can be useful for comparing the overall performance of similar models.</p>
<p>The best way to understand R<sup>2</sup> is that you use R<sup>2</sup> to report the proportion of the sum of squares explained by the model. For example, if R<sup>2</sup> equals 0.2, then 20 percent of the variance in Y is explained by the model. In the example above, none (0.00%) of the variance in party identification is explained by income. But in the first example, party identification alone predicted nearly 60% of the variation in the Donald Trump feeling thermometer.</p>
<p>Caveats for the use of correlation apply to R<sup>2</sup> as well (relative magnitude is most useful comparison).</p>
</div>
</div>
<div id="dummy-variables" class="section level2" number="6.6">
<h2>
<span class="header-section-number">6.6</span> Dummy variables<a class="anchor" aria-label="anchor" href="#dummy-variables"><i class="fas fa-link"></i></a>
</h2>
<p>Some research situations require using categorical or nominal variables (marital status, race, gender, religion, region) in the simple linear model. We use dummy or indicator variables to include this type of data in linear models.</p>
<p>For instance, region is coded from 1-4 in the NES. Is there any reason to expect that North Central region (coded 2) is half (by any measure) of the West (coded 4)? No. An alternative is to create a variable that identifies respondents from a group of interest as “1” with the rest as “0.”</p>
<div id="examples-of-dummy-variables" class="section level3 unnumbered">
<h3>Examples of dummy variables<a class="anchor" aria-label="anchor" href="#examples-of-dummy-variables"><i class="fas fa-link"></i></a>
</h3>
<div id="gender" class="section level4 unnumbered">
<h4>Gender<a class="anchor" aria-label="anchor" href="#gender"><i class="fas fa-link"></i></a>
</h4>
<p>I we were interested in the difference between people who identify as Male and people who identify as Female, we could create a dummy variable that has two categories</p>
<p><span class="math display">\[ X_1=
    \begin{cases}
      0, &amp; \text{if}\ Male \\
      1, &amp; \text{if} \ Female
    \end{cases}\]</span></p>
<p>Recall that <span class="math inline">\(Y=\beta_0+\beta_1X_1\)</span>. So the constant has a specific meaning when you have a single dummy variable.</p>
<p>When X is a dummy variable, the predicted value of Y is equal to the constant if X=0</p>
<p><span class="math display">\[Y=\beta_0\]</span></p>
<p>For X=1, the predicted value of Y is equal to the constant plus the slope coefficient:</p>
<p><span class="math display">\[Y=\beta_0+\beta_1\]</span></p>
<p>So while the focus remains on what the slope coefficient tells us about the difference between the two groups. But dummy variables also give us a simple way to deterine the level of Y for each group.</p>
<p>The example below uses a dummy variable of the type describe above to predict the level of the Donald Trump feeling thermometer.</p>
<p>Table 3. <strong>Donald Trump feeling thermometer and gender</strong></p>
<pre><code>
=========================================================
                        Feeling Thermometer, Donald Trump
---------------------------------------------------------
Female (dummy variable)             -5.441***            
                                    p = 0.000            
                                                         
Constant                            41.228***            
                                    p = 0.000            
                                                         
N                                     7,308              
R2                                    0.005              
Adjusted R2                           0.004              
=========================================================</code></pre>
<p>The numbers in the table tell us:</p>
<p>For women, Y = 41.2 + -5.4*1 = 35.8</p>
<p>For men, Y = 41.2 + -5.4*0 = 41.2</p>
<p>While the effect or link is statistically significant, so men are slightly warmer towards Trump, the effect is small (5 points).</p>
</div>
<div id="race" class="section level4 unnumbered">
<h4>Race<a class="anchor" aria-label="anchor" href="#race"><i class="fas fa-link"></i></a>
</h4>
<p>Using a dummy variable for race, we could directly compare the effect of race with the effect of gender. The ANES includes several categories that record the race of the respondents. In the 2020 ANES the categories are , 1. White, non-Hispanic, 2. Black, non-Hispanic, 3.Hispanic, 4. Asian, Native Hawaiian/other Pacific Islander, Native American/Alaska Native or multiple races, non-Hispanic</p>
<p>If the comparison of interest is White compared to Minority, we could create a dummy variable that takes two values: 0 (race=1) and 1 (anything but race=1)</p>
<p>The coefficients for a simple two variable model of Donald Trump feelings and race, using the dummy variable created above, appears below as Table 5.</p>
<p>Table 4. <strong>Donald Trump feeling thermometer and race {-}</strong></p>
<pre><code>
===========================================================
                          Feeling Thermometer, Donald Trump
-----------------------------------------------------------
Minority (dummy variable)            -16.269***            
                                      p = 0.000            
                                                           
Constant                              42.531***            
                                      p = 0.000            
                                                           
N                                       7,279              
R2                                      0.032              
Adjusted R2                             0.032              
===========================================================</code></pre>
<p>The regression output tells us that, for White respondents, Y = 42.5 + 16.3*0 = 42.5. For Minorities, Y = 42.5-16.3 = 26.2. So there is large difference between White and minority voters (16 points), but even White voters are –as a group- only are only lukewarm towards Donald Trump.</p>
<p>You can also see from the table that the impact of race is much bigger - the group differences (slope) is larger for race and the R<sup>2</sup> is larger.</p>
</div>
</div>
<div id="what-if-x-has-more-than-two-categories" class="section level3 unnumbered">
<h3>What if X has more than two categories?<a class="anchor" aria-label="anchor" href="#what-if-x-has-more-than-two-categories"><i class="fas fa-link"></i></a>
</h3>
<p>If you are interested in using a variable with many categories, then you need to use many dummy variables. If you have N categories, then you need N-1 dummy variables. In the examples above, we had two categories, so we need one dummy variable. If we wanted to test differences across all racial categories in the ANES (4 categories – white, black, Hispanic, other), then we would need 3 dummy variables. One category is the baseline category and the dummy variables represent the other category. We could select White as the baseline category and use dummy variables for Black, Hispanic, and Other. The link between the Donald Trump feeling thermometer and the race dummy variables is reproduced below.</p>
<p>Table 5. <strong>Donald Trump feeling thermometer and race (with four categories)</strong> {-}</p>
<pre><code>
=============================================
            Feeling Thermometer, Donald Trump
---------------------------------------------
Black                  -28.833***            
                        p = 0.000            
                                             
Hispanic               -12.277***            
                        p = 0.000            
                                             
Other                   -7.829***            
                       p = 0.00001           
                                             
Constant                42.531***            
                        p = 0.000            
                                             
N                         7,279              
R2                        0.045              
Adjusted R2               0.045              
=============================================</code></pre>
<p>As above, White respondents have a predicted value of 42.5. The predicted value for Black respondents is 28 points lower! Hispanic respondents are predicted to average 12 points lower. Other respondents are predicted to average about 8 points lower. So, overall, feeling thermometer responses were lower for Trump among each minority group. The R<sup>2</sup> for this model is a little higher than using a single dummy variable for race, so this model is a better fit for the ANES data.</p>
</div>
</div>
<div id="summary" class="section level2" number="6.7">
<h2>
<span class="header-section-number">6.7</span> Summary<a class="anchor" aria-label="anchor" href="#summary"><i class="fas fa-link"></i></a>
</h2>
<p>The linear model expresses the relationship between two variables. The dependent variable is predictable (more or less) based on the independent variable. Regression coefficients are measures of association between the variables, expressing magnitude and direction. Each coefficient in a linear regression is tested for statistical significance with a t-test. Is the coefficient different from zero in the population? A goodness-of-fit test statistic - R<sup>2</sup> summarizes the extent to which the independent variable(s) explain the level of the dependent variable. Dummy variables enable us to compare groups that can’t be ordered in any inherently meaningful way (the same circumstances that led us to use a t-test in Assignment #2).</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="measures-of-association-chi-square.html"><span class="header-section-number">5</span> Measures of association: Chi-square</a></div>
<div class="next"><a href="statistical-models-with-many-predictors.html"><span class="header-section-number">7</span> Statistical models with many predictors</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#regression"><span class="header-section-number">6</span> Regression</a></li>
<li><a class="nav-link" href="#why-not-just-use-simple-measures-of-association"><span class="header-section-number">6.1</span> Why not just use simple measures of association?</a></li>
<li>
<a class="nav-link" href="#ordinary-least-squares-regression-ols"><span class="header-section-number">6.2</span> Ordinary Least Squares regression (OLS)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#graphing-relationships-between-two-variables">Graphing relationships between two variables</a></li>
<li><a class="nav-link" href="#computation-in-the-simple-linear-model">Computation in the simple linear model</a></li>
<li><a class="nav-link" href="#how-restrictive-is-the-assumption-that-the-relationship-is-linear">How restrictive is the assumption that the relationship is linear?</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#interpreting-regression-coefficients"><span class="header-section-number">6.3</span> Interpreting regression coefficients</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#example-party-id-and-income-1">Example: Party id and income</a></li></ul>
</li>
<li>
<a class="nav-link" href="#hypothesis-testing-using-ols"><span class="header-section-number">6.4</span> Hypothesis testing using OLS</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-technical-note-on-the-t-test">A technical note on the t-test</a></li>
<li><a class="nav-link" href="#the-sampling-error-or-standard-deviation-of-beta_1">The sampling error or standard deviation of \(\beta_1\)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#evaluating-goodness-of-fit"><span class="header-section-number">6.5</span> Evaluating goodness-of-fit</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#using-r2-in-practice">Using R2 in practice</a></li></ul>
</li>
<li>
<a class="nav-link" href="#dummy-variables"><span class="header-section-number">6.6</span> Dummy variables</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#examples-of-dummy-variables">Examples of dummy variables</a></li>
<li><a class="nav-link" href="#what-if-x-has-more-than-two-categories">What if X has more than two categories?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary"><span class="header-section-number">6.7</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/JKCorder/RMD-for-AppStats-chapters/blob/master/06-ols.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/JKCorder/RMD-for-AppStats-chapters/edit/master/06-ols.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Applied Statistics for Political Science</strong>" was written by J.K. Corder. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
