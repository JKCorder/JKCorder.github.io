<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>6 Regression | Applied Statistics for Political Science</title>
<meta name="author" content="J.K. Corder">
<meta name="description" content="This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are...">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="6 Regression | Applied Statistics for Political Science">
<meta property="og:type" content="book">
<meta property="og:description" content="This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="6 Regression | Applied Statistics for Political Science">
<meta name="twitter:description" content="This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Applied Statistics for Political Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">About this book</a></li>
<li><a class="" href="data-science-political-science-and-public-policy.html"><span class="header-section-number">1</span> Data science, political science, and public policy</a></li>
<li><a class="" href="descriptive-statistics.html"><span class="header-section-number">2</span> Descriptive statistics</a></li>
<li><a class="" href="an-introduction-to-measures-of-association-correlation.html"><span class="header-section-number">3</span> An introduction to measures of association: correlation</a></li>
<li><a class="" href="measures-of-association-t-test.html"><span class="header-section-number">4</span> Measures of association: t-test</a></li>
<li><a class="" href="measures-of-association-chi-square.html"><span class="header-section-number">5</span> Measures of association: chi-square</a></li>
<li><a class="active" href="regression.html"><span class="header-section-number">6</span> Regression</a></li>
<li><a class="" href="statistical-models-with-many-predictors.html"><span class="header-section-number">7</span> Statistical models with many predictors</a></li>
<li><a class="" href="references.html">References</a></li>
<li><a class="" href="about-the-author.html">About the author</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/JKCorder/RMD-for-AppStats-chapters">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="regression" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Regression<a class="anchor" aria-label="anchor" href="#regression"><i class="fas fa-link"></i></a>
</h1>
<p>This chapter introduces a statistical modeling approach called regression or ordinary least squares regression, sometimes abbreviated as OLS. The idea is that we identify something we are interested in learning about or understanding, maybe why some people turn out to vote, or why they select a particular candidate, or whether or not they buy a product, or if they are diagnosed with lung cancer. We then select a number of things that we think we could use to predict these outcomes – a theory drives these choices. For turnout, is the person a partisan, are they educated? For a diagnosis of lung cancer, are they a smoker, are they older or younger? We then use data to test the link between the factors we think matter – the predictors – and the outcome of interest. OLS is the technique that we use to determine which factors do or do not matter.</p>
<p>Regression is widely used in a variety of contexts – from program evaluation to marketing to campaigns. If you work in an organization that routinely collects and analyzes data, someone in the organization will be using statistical models to make sense of that data and OLS may be one of the tools they use.</p>
<div id="why-not-just-use-simple-measures-of-association" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Why not just use simple measures of association?<a class="anchor" aria-label="anchor" href="#why-not-just-use-simple-measures-of-association"><i class="fas fa-link"></i></a>
</h2>
<p>The measures of association introduced in earlier chapters permitted us to evaluate the link between some dependent variable (<span class="math inline">\(Y\)</span>) and some independent variable (<span class="math inline">\(X\)</span>) with the specific objective of determining:</p>
<ul>
<li>What is the direction of the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>?</li>
<li>Is this effect large or small?</li>
<li>Is the sample effect statistically significant? (Can we infer something about the population from the data in our sample?)</li>
</ul>
<p>There are two important limitations to these measures of association.</p>
<p>First, we have a limited ability to convey or understand the magnitude of the relationship. If we observe a correlation of 0.4 between income and education, what does that mean? Yes, this would indicate that highly educated respondents are more likely to be high income, but how much income does a year of education add? What is the difference in predicted income between a high school graduate and a college graduate? This ambiguity also means that is challenging to directly compare the size of two effects evaluated with two different measures of association. How does the influence of race on party id (measured with a t-test) compare to the influence of income on party id (measured with a correlation)?</p>
<p>A second limitation is that we can only examine the effect of a single variable at one time – what if we expect that two or more variables are jointly responsible for the observed level of <span class="math inline">\(Y\)</span>?</p>
<p>An alternative to measures of association - the simple linear model – or regression – or Ordinary Least Squares regression – or OLS – permits us to manage both of these problems. In this chapter, we focus on a simple two variable model – which helps with problem of communicating specific information about the size of the effect. In Chapter 7, we extend the model to include more than one <span class="math inline">\(X\)</span> variable, to manage the second limitation above.</p>
</div>
<div id="ordinary-least-squares-regression-ols" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Ordinary Least Squares regression (OLS)<a class="anchor" aria-label="anchor" href="#ordinary-least-squares-regression-ols"><i class="fas fa-link"></i></a>
</h2>
<p>Linear regression assumes a particular “functional form” for the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, specifically that the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> can be summarized with a line (rather than a curve, or some other shape). A linear model takes this form:</p>
<p><span class="math display">\[Y=\beta_0+\beta_1X+\epsilon\]</span></p>
<ul>
<li><p><span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are known (data)</p></li>
<li><p><span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are estimated.</p></li>
<li><p><span class="math inline">\(e\)</span> is a random error</p></li>
</ul>
<p>We are principally interested in <span class="math inline">\(\beta_1\)</span> and we wish to know two things:</p>
<ul>
<li><p>What can we infer about the population from our observed <span class="math inline">\(\beta_1\)</span>?</p></li>
<li><p>What does the observed <span class="math inline">\(\beta_1\)</span> tell us about the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in the sample?</p></li>
</ul>
<p>The relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is assumed to be linear. This assumption imposes some structure on the link between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> which permits us to summarize the link between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> with a few parameters. If you recall high school geometry, you might remember that formula for a line is:</p>
<p><span class="math display">\[y=mx+b\]</span>
A line is fully and completely described by two parameters, <span class="math inline">\(m\)</span> and <span class="math inline">\(b\)</span>.</p>
<ul>
<li><p><span class="math inline">\(b\)</span> is the intercept (the point where the line crosses the vertical axis, <span class="math inline">\(x=0\)</span>)</p></li>
<li><p><span class="math inline">\(m\)</span> is the slope (rise/run) or <span class="math inline">\(\Delta{Y} / \Delta{X}\)</span></p></li>
</ul>
<p>The linear model takes the same form:</p>
<p><span class="math display">\[Y=\beta_0+\beta_1X\]</span></p>
<ul>
<li><p><span class="math inline">\(\beta_0\)</span> is the intercept</p></li>
<li><p><span class="math inline">\(\beta_1\)</span> is the slope (change in <span class="math inline">\(Y\)</span> for every one unit change in X). So,</p></li>
</ul>
<p><span class="math display">\[\beta_1=\frac{\Delta{Y}}{\Delta{X}}\]</span></p>
<p>And, rearranging terms,</p>
<p><span class="math display">\[\Delta{Y} = \Delta{X}*\beta_1\]</span></p>
<p>This calculation - the size of the change in <span class="math inline">\(Y\)</span> given a particular change in <span class="math inline">\(X\)</span> - will be the key way that we interpret and compare the size of effects using OLS.</p>
<div id="graphing-relationships-between-two-variables" class="section level3 unnumbered">
<h3>Graphing relationships between two variables<a class="anchor" aria-label="anchor" href="#graphing-relationships-between-two-variables"><i class="fas fa-link"></i></a>
</h3>
<p>The relationship between two variables may be linear, or it could take some other form – U-shaped or a curve. One way to understand the utility and use of the linear model is to produce a scatterplot of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to see what it means to assume the relationship is linear. The example below draws on data published by <span class="citation">Pollock (<a href="references.html#ref-pollock2011">2011</a>)</span> in an introductory text on social science statistics. The dependent variable (Y) is the percentage of state legislators who are women and the independent or predictor variable (X) is the percentage of state population who are Christian – “adhere to a Christian faith.”</p>
<p>A simple scatter plot of this data for the 50 U.S. states is reproduced as Figure 6.1, below.</p>
<strong>Figure <a href="regression.html#fig:figure61">6.1</a> Scatterrplot of women in the state legislature as a function of the proportion of state residents who are Christian</strong>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:figure61"></span>
<img src="images/states_scatter.png" alt="\label{fig:figure61}" width="90%"><p class="caption">
 
</p>
</div>
<p>Experiment with sketching the line in the figure above that you think best describes the link between the two variables. The line is obviously downward sloping: there are a higher proportion of women in the legislature in states that have a lower proportion of Christian adherents. But the line could be fairly steep - passing through 40 in the upper left and approach zero for <span class="math inline">\(X\)</span>=80. Or the line could be fairly flat – passing through 30 in the upper left and approach 10 for <span class="math inline">\(X\)</span>=80</p>
<p>What is best way to draw a line that describes the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>?</p>
<p>We are interested in the two parameters or numbers that describe the line that summarizes the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> – the slope and the intercept. What criteria should we use to pick one line over another? Maybe the distance between points and the line (lowest average error)? Maybe the squared distance between the points and the line (lowest sum of squared errors)? The second criteria – minimize squared error – is the approach we use. The actual regression line is added to the data in Figure <a href="regression.html#fig:figure62">6.2</a>, below.</p>
<strong>Figure <a href="regression.html#fig:figure62">6.2</a> Scatterplot of women in the state legislature as a function of the proportion of state residents who are Christian. with OLS line</strong>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:figure62"></span>
<img src="images/states_OLS.png" alt="\label{fig:figure62}" width="90%"><p class="caption">
 
</p>
</div>
<p>The line that best fits the data – that minimizes the sum of the squared distance between each point and the line – has a slope of -0.35 We can say some very specific things about the 50 states in the sample with this number. Since <span class="math inline">\(Y\)</span> is the percentage of state legislators who are women and <span class="math inline">\(X\)</span> is the percentage of state population who are Christian, we know from the formula above the <span class="math inline">\(\Delta{Y} = \Delta{X}*\beta_1\)</span> So if we compared a state with 70 percent Christian adherents to a state with 50 percent Christian adherents (<span class="math inline">\(\Delta{X}\)</span>=70-50 or 20), we would expect to see -0.35*20 or a 7 point drop in the predicted percentage of female legislators.</p>
</div>
<div id="computation-in-the-simple-linear-model" class="section level3 unnumbered">
<h3>Computation in the simple linear model<a class="anchor" aria-label="anchor" href="#computation-in-the-simple-linear-model"><i class="fas fa-link"></i></a>
</h3>
<p>Regression or OLS summarizes the data with a line that minimizes the sum of the squared error term (<span class="math inline">\(\epsilon^2\)</span>). For the bivariate model (one <span class="math inline">\(X\)</span> predicting Y), the computation of <span class="math inline">\(\beta_1\)</span> is simple. The sum of squared errors for any linear regression is minimized if:</p>
<p><span class="math display">\[\beta_1 =\frac{\sum((X-\mu_x)(Y-\mu_y))} {\sum(X-\mu_x)^2} \]</span></p>
<p>In words, the covariance of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> divided by the variance of X.</p>
<p>You can find the mathematical proof that gives the result in most introductory statistics texts.</p>
<p>One we have a value for <span class="math inline">\(\beta_1\)</span>, we can then calculate the intercept:</p>
<p><span class="math display">\[\beta_0=\mu_y-(\mu_x*\beta_1)\]</span></p>
<p>In words, the mean of <span class="math inline">\(Y\)</span> minus the product of the mean of <span class="math inline">\(X\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>We don’t care much about the constant term since we are mainly interested in comparing the levels across groups – group differences are going to matter more than whether all groups are high or all groups are low on Y. The formula for the intercept makes sure that average value of <span class="math inline">\(X\)</span> is associated with the average value of Y. If you rearrange the terms to solve for <span class="math inline">\(\mu_y\)</span> above, you can see that this approach will work.</p>
</div>
<div id="how-restrictive-is-the-assumption-that-the-relationship-is-linear" class="section level3 unnumbered">
<h3>How restrictive is the assumption that the relationship is linear?<a class="anchor" aria-label="anchor" href="#how-restrictive-is-the-assumption-that-the-relationship-is-linear"><i class="fas fa-link"></i></a>
</h3>
<p>The scatterplot in Figure 6.2 reveals two things about the data. First, there is a lot of error – this is a “noisy” relationship. States with 60 percent Christian adherents range from 5 percent to 35 percent females in the legislator. The second thing we learn is that, in this case, it appears reasonable to use a line to describe the data. We can evaluate this directly by permitting <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to be linked in a way other than a line. For an example, see Figure 6.3. The points are summarized with what is known as local “smoother” – so the squared distance between the points and the line is minimized, but the path of the line is determined by a handful of points in a narrow range of X, rather than the entire sample. Even with this very flexible approach, it appears the relationship is close to linear.</p>
<strong>Figure <a href="regression.html#fig:figure63">6.3</a> Scatterplot of women in the state legislature as a function of the proportion of state residents who are Christian, with local smoother.</strong>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:figure63"></span>
<img src="images/states_smooth.png" alt="\label{fig:figure63}" width="90%"><p class="caption">
 
</p>
</div>
</div>
</div>
<div id="interpreting-regression-coefficients" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> Interpreting regression coefficients<a class="anchor" aria-label="anchor" href="#interpreting-regression-coefficients"><i class="fas fa-link"></i></a>
</h2>
<p>The linear model assumes <span class="math inline">\(Y\)</span> is a linear function of X. Data are used to test if the relationship between <span class="math inline">\(X\)</span> and Y, the slope of the line, is positive, negative, or zero. You should have an idea of what you expect to observe before you generate the output. As was the case with measures of association, this expectation is formally labeled as the “alternative hypothesis.” In the simple linear model, we test our expectations by examining the sign (negative or positive) of <span class="math inline">\(\beta_1\)</span>.</p>
<p>A t-test is used to determine if the difference between the observed <span class="math inline">\(\beta_1\)</span> and zero is statistically significant. The null hypothesis is that <span class="math inline">\(\beta_1=0\)</span> in the population. The alternative hypothesis <span class="math inline">\(\beta_1\not=0\)</span> (not equal to zero).</p>
<p>If p&lt;0.05, then in the population <span class="math inline">\(\beta_1\)</span> is not equal to zero. (Formally, you reject the null hypothesis). The relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is statistically significant.</p>
<p>To see how regression works in practice, we use two examples – the link between the the Donald Trump feeling thermometer and party id and the link between income and party identification (introduced in Chapter 1).</p>
<div id="example-feelings-toward-donald-trump-and-party-identification" class="section level4 unnumbered">
<h4>
<strong>Example: Feelings toward Donald Trump and party identification</strong><a class="anchor" aria-label="anchor" href="#example-feelings-toward-donald-trump-and-party-identification"><i class="fas fa-link"></i></a>
</h4>
<p>How are attitudes about Donald Trump related to party id? Following the approach used in earlier chapters, the link between the Donald Trump feeling thermometer and and party identification is summarized in a line chart of group means. You can see that, on average, Strong Republicans love Donald Trump while Strong Democrats do not.</p>
<strong>Figure <a href="regression.html#fig:figure64">6.4</a> Donald Trump feeling thermometer, as a function of party identification</strong>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:figure64"></span>
<img src="06-ols_files/figure-html/figure64-1.png" alt="\label{fig:figure64}" width="90%"><p class="caption">
 
</p>
</div>
<p>So what exactly would a regression tell us? To get a sense of what we might expect, consider two questions. What exactly would you expect the feeling thermometer response to be for a Strong Democrat? What would you expect the feeling thermometer response to be for a Strong Republican? If you answered 85 for Strong Democrats and 25 for Strong Republicans, then you are expecting the slope of the regression line to be 10. Why is this the case? Recall the formula for the slope:</p>
<p><span class="math display">\[\beta_1=\Delta{Y}/\Delta{X}\]</span></p>
<p>So, if you expect the difference between strong Democrats and strong Republicans to be about 60 (<span class="math inline">\(\Delta{Y}\)</span>) and we know that the scale for party id ranges from 1 to 7, so <span class="math inline">\(\Delta{X}\)</span> is 7-1 or 6. We know that our expected slope is:</p>
<p><span class="math display">\[60/6 = 10\]</span></p>
<p>Review and make sure you understand the calculation in this example.</p>
<p>Part of the regression output for this model is reproduced as Table 1. We will first focus on the <em>coefficients</em> - the column of numbers next to the variable labels.</p>
<p><strong>Table <a href="#tab:model1">6.1</a> Donald Trump Trump feeling thermometer as a function of party id.</strong> <span style="color: white;">(#tab:model1)</span></p>
<pre><code>
======================================================
                     Feeling Thermometer, Donald Trump
------------------------------------------------------
Party identification             13.768***            
                                 p = 0.000            
                                                      
Constant                        -13.909***            
                                 p = 0.000            
                                                      
N                                  5,474              
R2                                 0.640              
Adjusted R2                        0.640              
======================================================</code></pre>
<p>For every unit increase in party id from 0-&gt;1, or from 1-&gt;2, the feeling thermometer increases by 13.9 points.</p>
<p>So the difference between strong Democrats (1) and strong Republicans (7) is equal to (7-1)*13.9 or 83 points! Even larger than we expected.</p>
<p>Notice the logic here: take the highest possible value of <span class="math inline">\(X\)</span> and subtract the lowest possible value of X. Multiply that number times the slope coefficient. The approximate size of the effect in the sample is:</p>
<p><span class="math display">\[(X_{max}-X_{min}) * \beta_1\]</span></p>
<p>Notice that the significance level associated with the coefficient is below 0.05 (p=0.000). This relationship is statistically significant. We can be confident that, in the population, strong Republicans have much higher average feeling thermometer responses than strong Democrats.</p>
</div>
<div id="example-party-id-and-income-1" class="section level3 unnumbered">
<h3>
<strong>Example: Party id and income</strong><a class="anchor" aria-label="anchor" href="#example-party-id-and-income-1"><i class="fas fa-link"></i></a>
</h3>
<p>In Chapter 1 we looked at the link between income and party identification, expecting that high income voters are more likely to identify with the Republican party than with the Democratic party. If <span class="math inline">\(Y\)</span> is party id from 1 to 7 with “7” designating strong Republicans and <span class="math inline">\(X\)</span> is income (on a scale from “1” designating $5,000 or lower household income and “22” designating $250,000 more), then <span class="math inline">\(\beta_1\)</span> should be positive.</p>
<p>The output from a linear regression testing the link between party id and income is reproduced as Table 2.</p>
<p><strong>Table <a href="#tab:model2">6.2</a> Party identification as a function of income.</strong>
<span style="color: white;">(#tab:model2)</span></p>
<pre><code>
================================
            Party identification
--------------------------------
Income            -0.007*       
                 p = 0.088      
                                
Constant          3.982***      
                 p = 0.000      
                                
N                  4,946        
R2                 0.001        
Adjusted R2        0.0004       
================================</code></pre>
<p>What do we learn? For every unit of income gained on the 22 point scale, your party id decreases by 0.007. So households with an income more than $250,000 (22) will really be no different on the party id scale than households with an income of under $9,999 (1), specifically ((22-1)*0.007)=0.15 points higher on the 1-7 scale – not very much - and we can also see that p-value is 0.086 so this result is not statistically significant. Consistent with what we saw in Chapter 3, there is no linear relationship between income and party id in 2020.</p>
<p>Interpretation of the meaning of the coefficient (<span class="math inline">\(\beta_1\)</span>) is the key to explaining the results of a regression.</p>
</div>
</div>
<div id="hypothesis-testing-using-ols" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> Hypothesis testing using OLS<a class="anchor" aria-label="anchor" href="#hypothesis-testing-using-ols"><i class="fas fa-link"></i></a>
</h2>
<p>In addition to using the output from the linear regression to learn about the direction and size the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in the sample, we also use the output to assess statistical significance and to evaluate how well the model fits the data.</p>
<div id="a-technical-note-on-the-t-test" class="section level3 unnumbered">
<h3>A technical note on the t-test<a class="anchor" aria-label="anchor" href="#a-technical-note-on-the-t-test"><i class="fas fa-link"></i></a>
</h3>
<p>The t-test is simply a one-sample t-test of whether or not <span class="math inline">\(\beta_1\)</span>=0.</p>
<p><span class="math display">\[t=\frac{\beta_1-0}{\sigma_{\beta_1}} \]</span></p>
<p>The top term is simply the difference between the observed coefficient and zero. The bottom term is the standard deviation for the coefficient. What is this number?</p>
</div>
<div id="the-sampling-error-or-standard-deviation-of-beta_1" class="section level3 unnumbered">
<h3>The sampling error or standard deviation of <span class="math inline">\(\beta_1\)</span><a class="anchor" aria-label="anchor" href="#the-sampling-error-or-standard-deviation-of-beta_1"><i class="fas fa-link"></i></a>
</h3>
<p>The slope coefficient has a sampling distribution just like other measures of association. If you took a number of samples, the average of the slopes would be the population slope and the standard deviation of the slope coefficient would be:</p>
<p><span class="math display">\[\sigma_{\beta_1} =\frac{\sum\epsilon^2} {\sum(X_i-\mu_x)^2 *(n-2)}\]</span></p>
<p>In words, the sum of squared errors divided by the variance of <span class="math inline">\(X\)</span> times n-2</p>
<p>This means we would expect to be very uncertain about estimates – to see a high; variance or standard deviation for <span class="math inline">\(\beta_1\)</span> - a lot of uncertainty under three conditions</p>
<ul>
<li>when n is not large (n-2 is small)</li>
<li>when the range of <span class="math inline">\(X\)</span> is narrow (variance of <span class="math inline">\(X\)</span> is small) or,</li>
<li>when the there is a lot of error or noise (sum of squared errors is large).</li>
</ul>
<p>Note the research design implications – if the goal is precision - to minimize the sampling variance of <span class="math inline">\(\beta_1\)</span>, then we would like: large n, sample values across the range of X, and a well-specified model (low errors).</p>
</div>
</div>
<div id="evaluating-goodness-of-fit" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> Evaluating goodness-of-fit<a class="anchor" aria-label="anchor" href="#evaluating-goodness-of-fit"><i class="fas fa-link"></i></a>
</h2>
<p>In addition to the coefficients and significance test, most regression output includes a useful and commonly used measure of the “goodness-of-fit” for each model estimated: the R<sup>2</sup> (or R-squared). The calculation is below:</p>
<p><span class="math display">\[R^2=1-\frac{\sum(Y-\widehat{Y})^2}{\sum(Y-\mu_y)^2}\]</span></p>
<p>The top half of the second term in the equation is designated the “residual sum of squares”: the sum of the differences of any individual <span class="math inline">\(Y\)</span> from the predicted <span class="math inline">\(Y\)</span> (Ŷ). This is some times labeled “error sum of squares”.</p>
<p>The bottom of the second term of the equation is the total sum of squares, which is the same as the variance of Y.</p>
<p>The value of R<sup>2</sup> is bounded between zero and one. You can never do worse than guessing that everyone in a sample will take the mean value of a variable. If then the second term of the equation above become 1 and the R<sup>2</sup> =0.</p>
<p>If, on the other hand, you your model perfectly predicted the outcome (Ŷ equals <span class="math inline">\(Y\)</span> for each observation), then the second term becomes zero and the R<sup>2</sup> would be one. R<sup>2</sup> is therefore bounded between zero and one. A low R<sup>2</sup> – closer to zero - indicates the model does not fit the data very well. In the example above, the R<sup>2</sup> is 0.0004, so this is a model that does not fit the data at all.</p>
<div id="using-r2-in-practice" class="section level3 unnumbered">
<h3>Using R<sup>2</sup> in practice<a class="anchor" aria-label="anchor" href="#using-r2-in-practice"><i class="fas fa-link"></i></a>
</h3>
<p>R<sup>2</sup> is not useful to compare different types of models (different levels of aggregation or very different dependent variables). R<sup>2</sup> can be useful for comparing the overall performance of similar models.</p>
<p>The best way to understand R<sup>2</sup> is that you use R<sup>2</sup> to report the proportion of the sum of squares explained by the model. For example, if R<sup>2</sup> equals 0.2, then 20 percent of the variance in <span class="math inline">\(Y\)</span> is explained by the model. In the example above, none (0.00%) of the variance in party identification is explained by income. But in the first example, party identification alone predicted nearly 60% of the variation in the Donald Trump feeling thermometer.</p>
<p>Caveats for the use of correlation apply to R<sup>2</sup> as well (relative magnitude is most useful comparison).</p>
</div>
</div>
<div id="dummy-variables" class="section level2" number="6.6">
<h2>
<span class="header-section-number">6.6</span> Dummy variables<a class="anchor" aria-label="anchor" href="#dummy-variables"><i class="fas fa-link"></i></a>
</h2>
<p>Some research situations require using categorical or nominal variables (marital status, race, gender, religion, region) in the simple linear model. We use dummy or indicator variables to include this type of data in linear models.</p>
<p>For instance, region is coded from 1-4 in the NES. Is there any reason to expect that North Central region (coded 2) is half (by any measure) of the West (coded 4)? No. An alternative is to create a variable that identifies respondents from a group of interest as “1” with the rest as “0”.</p>
<div id="examples-of-dummy-variables" class="section level3 unnumbered">
<h3>Examples of dummy variables<a class="anchor" aria-label="anchor" href="#examples-of-dummy-variables"><i class="fas fa-link"></i></a>
</h3>
<div id="gender" class="section level4 unnumbered">
<h4>Gender<a class="anchor" aria-label="anchor" href="#gender"><i class="fas fa-link"></i></a>
</h4>
<p>I we were interested in the difference between people who identify as Male and people who identify as Female, we could create a dummy variable that has two categories</p>
<p><span class="math display">\[ X_1=
    \begin{cases}
      0, &amp; \text{if}\ Male \\
      1, &amp; \text{if} \ Female
    \end{cases}\]</span></p>
<p>Recall that <span class="math inline">\(Y=\beta_0+\beta_1X_1\)</span>. So the constant has a specific meaning when you have a single dummy variable.</p>
<p>When <span class="math inline">\(X\)</span> is a dummy variable, the predicted value of <span class="math inline">\(Y\)</span> is equal to the constant if X=0</p>
<p><span class="math display">\[Y=\beta_0\]</span></p>
<p>For X=1, the predicted value of <span class="math inline">\(Y\)</span> is equal to the constant plus the slope coefficient:</p>
<p><span class="math display">\[Y=\beta_0+\beta_1\]</span></p>
<p>So while the focus remains on what the slope coefficient tells us about the difference between the two groups. But dummy variables also give us a simple way to deterine the level of <span class="math inline">\(Y\)</span> for each group.</p>
<p>The example below uses a dummy variable of the type describe above to predict the level of the Donald Trump feeling thermometer.</p>
<p><strong>Table <a href="#tab:model3">6.3</a> Donald Trump feeling thermometer and gender.</strong>
<span style="color: white;">(#tab:model3)</span></p>
<pre><code>
=========================================================
                        Feeling Thermometer, Donald Trump
---------------------------------------------------------
Female (dummy variable)             -6.428***            
                                    p = 0.000            
                                                         
Constant                            42.998***            
                                    p = 0.000            
                                                         
N                                     5,474              
R2                                    0.012              
Adjusted R2                           0.011              
=========================================================</code></pre>
<p>The numbers in the table tell us:</p>
<p>For women, <span class="math inline">\(Y\)</span> = 43.0 + -6.4*1 = 36.6</p>
<p>For men, <span class="math inline">\(Y\)</span> = 43.0 + -6.4*0 = 43.0</p>
<p>While the effect or link is statistically significant, so men are slightly warmer towards Trump, the effect is small (just over 6 points).</p>
</div>
<div id="race" class="section level4 unnumbered">
<h4>Race<a class="anchor" aria-label="anchor" href="#race"><i class="fas fa-link"></i></a>
</h4>
<p>Using a dummy variable for race, we could directly compare the effect of race with the effect of gender. The ANES includes several categories that record the race of the respondents. In the 2020 ANES the categories are , 1. White, non-Hispanic, 2. Black, non-Hispanic, 3.Hispanic, 4. Asian, Native Hawaiian/other Pacific Islander, Native American/Alaska Native or multiple races, non-Hispanic</p>
<p>If the comparison of interest is White compared to Minority, we could create a dummy variable that takes two values: 0 (race=1) and 1 (anything but race=1)</p>
<p>The coefficients for a simple two variable model of Donald Trump feelings and race, using the dummy variable created above, appears below as Table 5.</p>
<p><strong>Table <a href="#tab:model4">6.4</a> Donald Trump feeling thermometer and race.</strong>
<span style="color: white;">(#tab:model4)</span></p>
<pre><code>
===========================================================
                          Feeling Thermometer, Donald Trump
-----------------------------------------------------------
Minority (dummy variable)            -10.575***            
                                      p = 0.000            
                                                           
Constant                              42.688***            
                                      p = 0.000            
                                                           
N                                       5,443              
R2                                      0.015              
Adjusted R2                             0.014              
===========================================================</code></pre>
<p>The regression output tells us that, for White respondents, <span class="math inline">\(Y\)</span> = 42.7 + -10.6*0 = 42.7. For Minorities, <span class="math inline">\(Y\)</span> = 42.7-10.6 = 32.1. So there is large difference between White and minority voters (just over 10 points), but even White voters are –as a group- only are only lukewarm towards Donald Trump.</p>
<p>You can also see from the table that the impact of race is much bigger - the group differences (slope) is larger for race and the R<sup>2</sup> is larger.</p>
</div>
</div>
<div id="what-if-x-has-more-than-two-categories" class="section level3 unnumbered">
<h3>What if <span class="math inline">\(X\)</span> has more than two categories?<a class="anchor" aria-label="anchor" href="#what-if-x-has-more-than-two-categories"><i class="fas fa-link"></i></a>
</h3>
<p>If you are interested in using a variable with many categories, then you need to use many dummy variables. If you have N categories, then you need N-1 dummy variables. In the examples above, we had two categories, so we need one dummy variable. If we wanted to test differences across all racial categories in the ANES (4 categories – white, black, Hispanic, other), then we would need 3 dummy variables. One category is the baseline category and the dummy variables represent the other category. We could select White as the baseline category and use dummy variables for Black, Hispanic, and Other. The link between the Donald Trump feeling thermometer and the race dummy variables is reproduced below.</p>
<p><strong>Table <a href="#tab:model5">6.5</a> Donald Trump feeling thermometer and race (with four categories).</strong>
<span style="color: white;">(#tab:model5)</span></p>
<pre><code>
=============================================
            Feeling Thermometer, Donald Trump
---------------------------------------------
Black                  -21.771***            
                        p = 0.000            
                                             
Hispanic                -7.120***            
                       p = 0.00004           
                                             
Other                    -1.858              
                        p = 0.351            
                                             
Constant                42.688***            
                        p = 0.000            
                                             
N                         5,443              
R2                        0.027              
Adjusted R2               0.026              
=============================================</code></pre>
<p>As above, White respondents have a predicted value of 42.7. The predicted value for Black respondents is 21 points lower! Hispanic respondents are predicted to average 7 points lower. Other respondents are predicted to average about 2 points lower (but, not statistically significant). So, overall, feeling thermometer responses were lower for Trump among two of three minority groups. The R<sup>2</sup> for this model is a little higher than using a single dummy variable for race, so this model is a better fit for the ANES data.</p>
</div>
</div>
<div id="summary" class="section level2" number="6.7">
<h2>
<span class="header-section-number">6.7</span> Summary<a class="anchor" aria-label="anchor" href="#summary"><i class="fas fa-link"></i></a>
</h2>
<p>The linear model expresses the relationship between two variables. The dependent variable is predictable (more or less) based on the independent variable. Regression coefficients are measures of association between the variables, expressing magnitude and direction. Each coefficient in a linear regression is tested for statistical significance with a t-test. Is the coefficient different from zero in the population? A goodness-of-fit test statistic - R<sup>2</sup> summarizes the extent to which the independent variable(s) explain the level of the dependent variable. Dummy variables enable us to compare groups that can’t be ordered in any inherently meaningful way (the same circumstances that led us to use a t-test in Problem Set 2).</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="measures-of-association-chi-square.html"><span class="header-section-number">5</span> Measures of association: chi-square</a></div>
<div class="next"><a href="statistical-models-with-many-predictors.html"><span class="header-section-number">7</span> Statistical models with many predictors</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#regression"><span class="header-section-number">6</span> Regression</a></li>
<li><a class="nav-link" href="#why-not-just-use-simple-measures-of-association"><span class="header-section-number">6.1</span> Why not just use simple measures of association?</a></li>
<li>
<a class="nav-link" href="#ordinary-least-squares-regression-ols"><span class="header-section-number">6.2</span> Ordinary Least Squares regression (OLS)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#graphing-relationships-between-two-variables">Graphing relationships between two variables</a></li>
<li><a class="nav-link" href="#computation-in-the-simple-linear-model">Computation in the simple linear model</a></li>
<li><a class="nav-link" href="#how-restrictive-is-the-assumption-that-the-relationship-is-linear">How restrictive is the assumption that the relationship is linear?</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#interpreting-regression-coefficients"><span class="header-section-number">6.3</span> Interpreting regression coefficients</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#example-party-id-and-income-1">Example: Party id and income</a></li></ul>
</li>
<li>
<a class="nav-link" href="#hypothesis-testing-using-ols"><span class="header-section-number">6.4</span> Hypothesis testing using OLS</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#a-technical-note-on-the-t-test">A technical note on the t-test</a></li>
<li><a class="nav-link" href="#the-sampling-error-or-standard-deviation-of-beta_1">The sampling error or standard deviation of \(\beta_1\)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#evaluating-goodness-of-fit"><span class="header-section-number">6.5</span> Evaluating goodness-of-fit</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#using-r2-in-practice">Using R2 in practice</a></li></ul>
</li>
<li>
<a class="nav-link" href="#dummy-variables"><span class="header-section-number">6.6</span> Dummy variables</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#examples-of-dummy-variables">Examples of dummy variables</a></li>
<li><a class="nav-link" href="#what-if-x-has-more-than-two-categories">What if \(X\) has more than two categories?</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary"><span class="header-section-number">6.7</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/JKCorder/RMD-for-AppStats-chapters/blob/master/06-ols.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/JKCorder/RMD-for-AppStats-chapters/edit/master/06-ols.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Applied Statistics for Political Science</strong>" was written by J.K. Corder. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
